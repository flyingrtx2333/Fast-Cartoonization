# Fast-Cartoonization

ä¸€ç§é«˜é€Ÿå›¾ç‰‡å¡é€šåŒ–çš„è½¬ç»˜æ¨¡å‹

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

ä¸ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯"é»‘ç›’"å¡é€šåŒ–æ–¹æ³•ä¸åŒï¼Œç™½ç›’å¡é€šåŒ–æ–¹æ³•å°†å¡é€šé£æ ¼åˆ†è§£ä¸ºä¸‰ä¸ªå¯è§£é‡Šçš„è¡¨ç¤ºï¼š

1. **è¡¨é¢è¡¨ç¤º (Surface)** - å¹³æ»‘çš„é¢œè‰²å—
2. **ç»“æ„è¡¨ç¤º (Structure)** - æ¸…æ™°çš„è¾¹ç¼˜å’Œè½®å»“  
3. **çº¹ç†è¡¨ç¤º (Texture)** - çº¹ç†ç»†èŠ‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### æ¨ç†ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰

```bash
python inference.py \
    --input ./test_images \
    --output ./results \
    --checkpoint ./checkpoints/generator.pth
```

### å•å¼ å›¾ç‰‡å¤„ç†

```bash
python inference.py \
    --input photo.jpg \
    --output cartoon.jpg \
    --checkpoint ./checkpoints/generator.pth
```

## ğŸ‹ï¸ è®­ç»ƒ

### 1. å‡†å¤‡æ•°æ®é›†

ç»„ç»‡æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
dataset/
â”œâ”€â”€ photo/           # çœŸå®ç…§ç‰‡ (è®­ç»ƒç”¨)
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ cartoon/         # å¡é€šå‚è€ƒå›¾ç‰‡
    â”œâ”€â”€ cartoon1.jpg
    â”œâ”€â”€ cartoon2.jpg
    â””â”€â”€ ...
```

**æ¨èæ•°æ®æ¥æºï¼š**
- é£æ™¯ç…§ç‰‡ï¼šä»»æ„é«˜è´¨é‡é£æ™¯å›¾ç‰‡
- å¡é€šå›¾ç‰‡ï¼šæ–°æµ·è¯šã€å®«å´éªã€ç»†ç”°å®ˆç­‰åŠ¨ç”»ç”µå½±æˆªå¸§
- äººåƒç…§ç‰‡ï¼šé«˜è´¨é‡äººåƒç…§ç‰‡
- äººåƒå¡é€šï¼šäº¬éƒ½åŠ¨ç”»ã€PA Works ç­‰ä½œå“

### 2. é¢„è®­ç»ƒç”Ÿæˆå™¨

é¦–å…ˆé¢„è®­ç»ƒç”Ÿæˆå™¨è¿›è¡Œå›¾åƒé‡å»ºï¼š

```bash
python pretrain.py \
    --photo_dir ./dataset/photo \
    --save_dir ./pretrain_results \
    --batch_size 16 \
    --num_iters 50000 \
    --lr 2e-4
```

### 3. å®Œæ•´è®­ç»ƒ

ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå®Œæ•´çš„å¯¹æŠ—è®­ç»ƒï¼š

```bash
python train.py \
    --photo_dir ./dataset/photo \
    --cartoon_dir ./dataset/cartoon \
    --pretrain_path ./pretrain_results/checkpoints/pretrain_final.pth \
    --save_dir ./train_results \
    --batch_size 16 \
    --num_iters 100000 \
    --lr 2e-4 \
    --lambda_surface 0.1 \
    --lambda_structure 1.0 \
    --lambda_content 200.0 \
    --lambda_tv 10000.0
```

### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--batch_size` | 16 | æ‰¹æ¬¡å¤§å° |
| `--num_iters` | 100000 | è®­ç»ƒè¿­ä»£æ¬¡æ•° |
| `--lr` | 2e-4 | å­¦ä¹ ç‡ |
| `--lambda_surface` | 0.1 | è¡¨é¢æŸå¤±æƒé‡ |
| `--lambda_structure` | 1.0 | ç»“æ„æŸå¤±æƒé‡ |
| `--lambda_content` | 200.0 | å†…å®¹æŸå¤±æƒé‡ |
| `--lambda_tv` | 10000.0 | æ€»å˜å·®æŸå¤±æƒé‡ |

## ğŸ“¦ æ¨¡å‹å¯¼å‡º

### å¯¼å‡ºåˆ° ONNX

```bash
python export.py \
    --checkpoint ./train_results/generator_final.pth \
    --output_dir ./exported_models \
    --onnx \
    --input_size 256
```

### å¯¼å‡ºåˆ° CoreML (iOS)

```bash
python export.py \
    --checkpoint ./train_results/generator_final.pth \
    --output_dir ./exported_models \
    --coreml \
    --input_size 256
```

### å¯¼å‡ºæ‰€æœ‰æ ¼å¼

```bash
python export.py \
    --checkpoint ./train_results/generator_final.pth \
    --output_dir ./exported_models \
    --all
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
MyCartoonization/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py        # UNet ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ discriminator.py    # è°±å½’ä¸€åŒ–åˆ¤åˆ«å™¨
â”‚   â”œâ”€â”€ guided_filter.py    # å¯¼å‘æ»¤æ³¢å™¨
â”‚   â””â”€â”€ vgg.py              # VGG ç‰¹å¾æå–
â”œâ”€â”€ dataset.py              # æ•°æ®é›†ç±»
â”œâ”€â”€ losses.py               # æŸå¤±å‡½æ•°
â”œâ”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”œâ”€â”€ pretrain.py             # é¢„è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train.py                # å®Œæ•´è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py            # æ¨ç†è„šæœ¬
â”œâ”€â”€ export.py               # æ¨¡å‹å¯¼å‡º
â”œâ”€â”€ requirements.txt        # ä¾èµ–
â””â”€â”€ README.md               # è¯´æ˜æ–‡æ¡£
```

## ğŸ”§ æ¨¡å‹æ¶æ„

### ç”Ÿæˆå™¨ (UNet Generator)

- ç¼–ç å™¨ï¼š3ä¸ªä¸‹é‡‡æ ·å—
- ç“¶é¢ˆå±‚ï¼š4ä¸ªæ®‹å·®å—
- è§£ç å™¨ï¼š3ä¸ªä¸Šé‡‡æ ·å— + è·³è·ƒè¿æ¥
- æ¿€æ´»å‡½æ•°ï¼šLeakyReLU

### åˆ¤åˆ«å™¨ (Spectral Norm Discriminator)

- PatchGAN æ¶æ„
- è°±å½’ä¸€åŒ–ç¨³å®šè®­ç»ƒ
- ä¸¤ä¸ªåˆ¤åˆ«å™¨ï¼šè¡¨é¢ (3é€šé“) + ç»“æ„ (1é€šé“)

### å¯¼å‘æ»¤æ³¢å™¨ (Guided Filter)

- è¾¹ç¼˜ä¿æŒå¹³æ»‘
- å¯å¾®åˆ†å®ç°
- å‚æ•°ï¼šr=1, eps=5e-3

## ğŸ“Š æŸå¤±å‡½æ•°

| æŸå¤± | æƒé‡ | è¯´æ˜ |
|------|------|------|
| Surface GAN | 0.1 | æ¨¡ç³Šåå›¾åƒçš„å¯¹æŠ—æŸå¤± |
| Structure GAN | 1.0 | ç°åº¦å›¾åƒçš„å¯¹æŠ—æŸå¤± |
| Content (VGG) | 200 | VGG conv4_4 æ„ŸçŸ¥æŸå¤± |
| Total Variation | 10000 | å¹³æ»‘åº¦çº¦æŸ |

## ğŸ¯ ä½¿ç”¨ Python API

```python
from inference import Cartoonizer

# åˆ›å»ºå¡é€šåŒ–å™¨
cartoonizer = Cartoonizer(
    checkpoint_path='./checkpoints/generator.pth',
    device='cuda'
)

# å¤„ç†å›¾ç‰‡
import cv2
img = cv2.imread('photo.jpg')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

result = cartoonizer.cartoonize(img)

# ä¿å­˜ç»“æœ
result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)
cv2.imwrite('cartoon.jpg', result)
```

## âš™ï¸ ç³»ç»Ÿè¦æ±‚

- Python >= 3.8
- PyTorch >= 2.0
- CUDA >= 11.7 (æ¨èï¼Œç”¨äºGPUè®­ç»ƒ)
- å†…å­˜ >= 8GB RAM
- æ˜¾å­˜ >= 8GB VRAM (ç”¨äºè®­ç»ƒ)

## ğŸ“š å‚è€ƒ

- åŸè®ºæ–‡ï¼š[Learning to Cartoonize Using White-Box Cartoon Representations](https://systemerrorwang.github.io/White-box-Cartoonization/)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚å•†ä¸šä½¿ç”¨è¯·å‚è€ƒåŸè®ºæ–‡çš„è®¸å¯è¯è¦æ±‚ã€‚

```bibtex
@InProceedings{Wang_2020_CVPR,
    author = {Wang, Xinrui and Yu, Jinze},
    title = {Learning to Cartoonize Using White-Box Cartoon Representations},
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2020}
}
```

